{
  "index.html": {
    "href": "index.html",
    "title": "TrainAR | TrainAR Documentation",
    "keywords": "TrainAR TrainAR is a holistic threefold combination of an interaction concept, didactic framework and authoring tool for Augmented Reality (AR) trainings on handheld Android and iOS devices ( Blattgerste et al. 2021 ). It is completely open source, free and offers non-programmers and programmers without AR-specific expertise aiding in the creation of interactive, engaging, procedural Augmented Reality trainings. This repository contains the technical components of the interaction concept and authoring tool of TrainAR in form of a custom Unity 2022.1. Editor Extension. It can be used with the Unity Windows, macOS (Silicon), macOS (Intel), or Linux Editor and deploy to Android and iOS devices. The authoring tool already offers features like the onboarding animations, tracking solutions, assembly placements, evaluated interaction concepts, layered feedback modalities and training assessments of TrainAR out of the box. This allows authors of AR trainings to focus on the content of the training instead of technical challenges. Authors can simply import 3D models into the tool, convert them to TrainAR objects and reference them in a visual-scripting stateflow (that is inspired by work-process-analyses) to create a procedural flow of instructions, user actions and feedback. The idea behind TrainAR is simple: Realistic deployments of head-mounted AR devices still remain a challenge today because of high costs, missing relevant training, and novelty of interactions that require in-depth onboarding. In contrast, smartphone-based AR would be realistically scalable today, while still retaining many of the learning benefits. At least in theory. While possible, most mobile AR learning applications focus on visualisation instead of interactions today, severely limiting their application scope. In line with recent findings that, in terms of training outcome, tangible interactions are not significantly increasing retention or transfer of knowledge compared to purely virtual interaction approaches ( Knierim et al. 2020 ), the idea of TrainAR is a holistic and scalable solution for procedural task training using Augmented Reality on handheld AR devices. Hereby, the idea is not to replace practical trainings but use TrainAR scenarios for concept and procedure understanding in preparation for or retention training after the practical training sessions. In line with Gagne 1984 , it is envisioned as a novel type of multimedia source to train intellectual skills and cognitive strategies but does not train associated motor skills . TrainAR Training Scenarios Several TrainAR trainings were already developed by us, researchers from partner universities, and students using preliminary versions of the TrainAR authoring tool. They span across the contexts of medical education, nursing education, chemical engineering, science educational, manual assembly, and everyday work tasks. A list of publications for some of the trainings can be found below. Documentation & Getting Started If you want to try out already developed TrainAR trainings, here is a list of available Apps that utilize TrainAR: Training scenario \"Preparation of a tocolytic injection\" in the Heb@AR App [ Youtube , Android & iOS ] Training scenario \"Pelvis Termini\" in the Heb@AR App [ Youtube , Android & iOS ] If you want to get started with creating, deploying and playing with your own TrainAR training, check out our Getting Started Guide . You can either use the example scenario that ships with this repository, or create a very simple example scene from the guide in less than half an hour. Beyond the Getting Started Guide, a full documentation is available detailing the available visual scripting nodes , how to create TrainAR objects and how to use nodes to implement action flows . Additionally, a complete documentation of all API references is included. A key idea behind TrainAR is the retention of the full Unity capabilities while offering a higher-level abstraction for non-programmers to get started with AR authoring. Therefore, it can also be utilized without the visual scripting and without the TrainAR authoring overlay, using the standard Unity Editor Overlay and C# programming. This could for example be interesting, if you want to implement non-procedural educational games or you are only interested in the components of the interaction concept and not so much the authoring tool itself. For this, check out the Advanced Options documentation. Contributing to this Project TrainAR is envisioned as a participatory project, continously improving and expanding it's quality and scope. Feel free to contribute to its source code, documentation or conceptual/didactic ideas through Issues or Discussions . You are using TrainAR for an Augmented Reality training or learning game? Show us what you created! You are using TrainAR to explore Augmented Reality trainings in a new context as your scientific research? Feel free to add your publications to our list of publications below so others can use it as a reference. Publication List TrainAR Framework: Blattgerste, J., Janßen, S., Behrends, J., & Pfeiffer, T. (Forthcoming). TrainAR: An Open Source Visual Scripting-based Authoring Tool for Procedural Mobile Augmented Reality Trainings . Blattgerste, J., Luksch, K., Lewa, C., & Pfeiffer, T. (2021). TrainAR: A Scalable Interaction Concept and Didactic Framework for Procedural Trainings Using Handheld Augmented Reality . Multimodal Technologies and Interaction, 5(7), 30. TrainAR Trainings: Arztmann, M., Domínguez Alfaro, J. L., Blattgerste, J., Jeuring, J., Van Puyvelde, P. (2022). Marie’s ChemLab: a Mobile Augmented Reality Game to Teach Basic Chemistry to Children .European Conference on Games Based Learning. Domínguez Alfaro, J. L., Gantois, S., Blattgerste, J., De Croon, R., Verbert, K., Pfeiffer, T., & Van Puyvelde, P. (2022). Mobile Augmented Reality Laboratory for Learning Acid–Base Titration . Journal of Chemical Education, 99(2), 531–537. Blattgerste, J., Vogel, K., Lewa, C., Willmeroth, T., Joswig, M., Schäfer, T., ... & Pfeiffer, T. (2022). The Heb@ AR App–Five Augmented Reality Trainings for Self-Directed Learning in Academic Midwifery Education . DELFI 2022 – Die 20. Fachtagung Bildungstechnologien der Gesellschaft für Informatik eV. Blattgerste, J., Luksch, K., Lewa, C., Kunzendorf, M., Bauer, N. H., Bernloehr, A., ... & Pfeiffer, T. (2020). Project Heb@AR: Exploring handheld Augmented Reality training to supplement academic midwifery education . DELFI 2020 – Die 18. Fachtagung Bildungstechnologien der Gesellschaft für Informatik eV. Funding The research resulting in the open source TrainAR project was partially supported by the grant 16DHB3021, project \"HebAR - AR-Based-Training-Technology\", by the German Ministry for Education and Research (BMBF) [ 1 ] and partially by the Mixed Reality Lab at University of Applied Sciences Emden/Leer. TrainAR is the abstraction and generalization of interaction concepts, feedback mechanisms, and didactic ideas developed during Project Heb@AR [ 1 , 2 ]. Here, procedural Augmented Reality emergency trainings were explored in the academic midwifery education context. During the development it became clear that those concepts could also be generalized towards other training contexts and thus we share TrainAR here. Acknowledgement TrainAR is freely accessible for commercial and non-commercial use under the MIT license and does not require acknowledgement in your TrainAR training or App itself. If you use TrainAR in the scientific context though, please acknowledge it by citing our publications on the interaction concept, didactic considerations and the authoring tool itself: @article{blattgerste2021trainar, title={TrainAR: A Scalable Interaction Concept and Didactic Framework for Procedural Trainings Using Handheld Augmented Reality}, author={Blattgerste, Jonas and Luksch, Kristina and Lewa, Carmen and Pfeiffer, Thies}, journal={Multimodal Technologies and Interaction}, volume={5}, number={7}, pages={30}, year={2021}, publisher={Multidisciplinary Digital Publishing Institute} }"
  },
  "manual/ActionNodes.html": {
    "href": "manual/ActionNodes.html",
    "title": "Action Nodes | TrainAR Documentation",
    "keywords": "Action Nodes TrainAR: Action nodes define, which are the correct actions to take for the user in the AR-Training. There are action nodes that require an input in the AR-Context, so interactions with or combination of TrainAR Objects, but there are also action nodes which require input of the user on the user interface (UI Action Nodes), which are documented separately in the UI Action Node documentation. AR interactions with Action Nodes Interacting with TrainAR Objects in the AR context is possible in two ways: interacting and combining . The node can be set to the type of interaction via the \"Action\" drop down menu. This node is set to Interaction. If the stateflow reaches this point, the node waits for an action by the user. If the user triggers an interact with the TrainAR Object specified in Correct object , the stateflow continues according to the Correct -Output of the node. Consequently, if any other action is taken by the user, the stateflow continues according to the Incorrect -Output of the node. For Combinations the node works similarly, though two objects have to be specfied: the grabbed objects, so the one the user is currently holding, and the object the grabbed object is supposed to be combined with. Custom Action With the Action Node set to Custom Action it is also possible to control the stateflow with your own custom actions/triggers as described in the Advanced Options . In that case, you need to request a state change to the StatemachineConnector with a parameter. This parameter is checked against the parameter defined in the node and then determined as either Correct or Incorrect - the stateflow then resumes accordingly. In this example the correct parameter is defined as \"correctParameter\". The following example describes how to request a state change to the StatemachineConnector through C# scripting: parameterToCheck = \"correctParameter\"; StatemachineConnector.Instance.RequestStateChange(new StateInformation(parameter: parameterToCheck)); parameterToCheck = \"wrongParameter\"; StatemachineConnector.Instance.RequestStateChange(new StateInformation(parameter: parameterToCheck)); In the first call to the StatemachineConnector the stateflow continues according to the Correct -output of the node, since parameterToCheck is set to the the correct parameter. The second call to the StatemachineConnector results in triggering the Incorrect -output of the node, since this is not the parameter specified in the node. TrainAR: Action (Fork) Sometimes you may run into situations where the training procedure you're creating has multiple correct actions at one point. Maybe those actions might even result in a different stateflow after this point. e.g. because there is multiple orders for sub-sequences of the procedure. TrainAR: Action (Fork) let you specify multiple correct actions and the stateflow these actions are supposed to result in. The number specified in the Action count field defines the number of TrainAR Objects with whom an action is considered correct. Consequently, if the number is changed, the node adjusts itself, so the specified number of Correct objects and their stateflows can be defined. This of course also works analogous with Combinations . TrainAR Action (Multi) In other cases when creating your training you might run into situations, where multiple actions have to happen, but it doesn't necessarily have to be in in a strict order (e.g. combining multiple TrainAR Objects like vegetables with a soup bowl). These cases can be modeled with the TrainAR: Action (Multi) node. The All correct stateflow is triggered once, when all of the defined actions have been performed. If any other actions is registered, the incorrect stateflow is triggered repeatedly on each incorrect action."
  },
  "manual/FeedbackNode.html": {
    "href": "manual/FeedbackNode.html",
    "title": "Feedback Node | TrainAR Documentation",
    "keywords": "Feedback Node The Feedback Node triggers an UI-Overlay, which covers the whole smartphone screen and displays feedback to the user. Therefore it's recommended use is for espeacially important textual feedback, where a simple red blinking outline would not be sufficient. In the node, a header text and the feedback text have to be specified. From the didactic perspective, this is intended to be used to provide feedback to the user of the training: Telling the user what he did wrong or what he could do to continue. For more detail, read our publication on the TrainAR interaction concept and didactic framework: \"TrainAR: A Scalable Interaction Concept and Didactic Framework for Procedural Trainings Using Handheld Augmented Reality\" TrainAR Node Result"
  },
  "manual/GettingStarted.html": {
    "href": "manual/GettingStarted.html",
    "title": "Getting Started Guide | TrainAR Documentation",
    "keywords": "Getting Started Guide The Getting Started Guide is meant to provide a \"quickstart\" for your development of TrainAR trainings and guides you through the process of creating a very simple TrainAR training from scratch. This Getting Started Guide presumes that you already completed the Installation & Setup of Unity and TrainAR. There is a training assembly included in the TrainAR repository that can be deployed directly for testing. You can also try to deploy and test this example first and play around with it as we will delete this shortly: For this, directly skip to \" Deploy your training to your phone \". Delete the example TrainAR training If you started the TrainAR Unity project with Unity Version 2022.1 through the Unity HUB (as described in Installation & Setup ) and opened the TrainAR Authoring Tool through the top-panel menu item called \"TrainAR\" -> \"Open TrainAR Authoring Tool\". You should now see the TrainAR Authoring Tool roughly like this: As you can see, there already is a TrainAR training. But we want to develop a TrainAR training from scratch and therefore have to delete the example training. For this we have to delete all TrainAR Objects and the TrainAR stateflow. To accomplish this, we can click somewhere into the Scene (blue) press CTRL + A and then Delete / DEL ( Backspace on macOS) to delete all TrainAR Objects. Afterwards, click somewhere into the Scripting Graph (red) and then again press CTRL + A to select the complete stateflow in the TrainAR statemachine. Deselect the very first node (\"TrainAR: Onboarding completed and training assembly placed\"), as we need this for each training. Then press Delete / DEL ( Backspace on macOS). This deletes the complete TrainAR Stateflow. and the TrainAR Authoring Tool should look roughly like this: In the scene window you should now still see the reference setup of the current Workspace (a room of black tiles, a table and a female character) but no TrainAR Objects in the Hierarchy or Scene and only the very first, green \"TrainAR: Onboarding completed and training assembly placed\" node. The reference setup should give you an idea of the size of objects in regards to the real world when viewed in the authoring tool and is not deployed with the TrainAR training. Create TrainAR Objects On the left in the Hierarchy tab is a (currently empty) list of the objects in the scene. On the Bottom Left, in the Project Tab open the Prefabs folder. There is a Prefab named Spoon_Prefab . Click on this Prefab and drag-and-drop it into the Hierarchy Tab. The spoon should appear on the table. To interact with this object, you'll need to unpack the prefab and then convert it to a TrainAR Object. You do this by right-clicking on it in the Hierarchy Tab and select Prefab and in the submenu Unpack Completely . Then right-click on it again and select Convert to TrainAR Object . You may then change the name of the object. This step is not necessary if provided models are not Prefabs, therefore they are in black/white Text instead of blue, e.g. if they come from 3D scanning or external 3D asset libraries. Prefabs are mostly used when downloading 3D assets from the Unity Assetstore. You can move the newly created TrainAR object around, rotate it or change its size. To do this, you can switch between different tools in the Tools tab in the Scene View. For now make sure the Move tool is selected and move the object in a fitting position on the reference-table. Now add Coffee_Tin_Prefab from the Prefabs folder, unpack it and convert it to an TrainARObject, then position it. Your setup should now look kind of like this: Good! You converted and placed some TrainAR Objects onto the Training Assembly. You could already deploy this training to a device and see your objects in AR but they would not elicit any behaviour or feedback based on the users actions. For this we have to connect the TrainAR Objects in our TrainAR Stateflow. Create a TrainAR Stateflow In the Bottom of the Unity window you should see the window with the Script Graph Tab. Here you can create the flow of your training by creating nodes and connecting them. There already is one node in the Script Graph with the description TrainAR: Onboarding completed and training assembly placed . This is the entry point of your training flow and makes sure that when you training starts, TrainAR already handled onboarding and the training assembly was placed into a valid position by the user. Right click into the Script Graph Window and select TrainAR from the Node Menu. From there, select TrainAR: Action . The TrainAR Action node should appear in the Stateflow. There are two types of action you can define: Interaction and Combination. For now leave the chosen action to Interaction. In the TrainAR: Action node under the Correct Action textfield type in Spoon . Now connect the two nodes by clicking on the output of the TrainAR: Onboarding completed and training assembly placed node and connecting the line with the input of the TrainAR: Action node. You have now defined that, at this point in the stateflow (the very start), the correct next step is to trigger an Interaction on the TrainAR Object Spoon . Right click again in the Script Graph window to open the node menu and select the TrainAR: Feedback node in the TrainAR nodes folder. This node opens an error overlay. Type a fitting error messages in the textfield and connect the Incorrect output of the TrainAR: Action node with the Input of the TrainAR: Feedback node. You have now defined what happens if an incorrect action is taken at this point in the stateflow. Now define what should happens if the correct action is taken. Create another TrainAR: Feedback node and type in feedback for the correct action taken and connect it to the correct output of the TrainAR: Action node. Note: This is for demonstration purposes only, Feedback nodes should normally be used for errors and not positive feedback as described in the didactic considerations of our research paper: TrainAR: A Scalable Interaction Concept and Didactic Framework for Procedural Trainings Using Handheld Augmented Reality . Now create another TrainAR: Action node and connect it to the TrainAR Feedback for the correct feedback. Select Combination as an Action in the node. Under Correct Grabbed Object type in Spoon and under Correct stationary Object type in Coffee_Tin . Connect the nodes. You have now defined, that at this point in the stateflow, the correct step is to combine the spoon with the coffee tin. Next you'll have to define what happens as a result. Let's make the combine fill up the spoon. To do this add a TrainAR: Object Helper node to the stateflow. In the node, set the dropdown menu to Replace Mesh and type in the Object Name field Spoon . In the Project Tab navigate to the Meshes folder and drag-and-drop the SpoonFilled mesh into the mesh field of the node. Then, drag-and-drop the SpoonFilled material from the Materials folder into the material field. Finally, connect the stateflow. This basically tells TrainAR, that we want to replace this objects shape and texture as a result of this action (because now there is coffee in it). Afterwards, add a TrainAR: Action (UI) node. A node that can trigger UI Custom Actions. Set the dropdown menu in the node you just created to Questionnaire . A UI action node waits for user input on the UI before it continues in a stateflow. In this example, we'll simply ask the user whether or not he want's to finish the training. Therefore write a fitting Questiontext in the Question field of the node and add some chooseable answers. Don't forget to connect the stateflow of the previous node. Finally, create a TrainAR: Training Conclusion node and connect the node from the previous step with it. This tells TrainAR to show the TrainAR Training Assessment and that we are done with the training. Done! The full process from start to finish Here is the full process of creating this simple training from scratch in one go: Deploy your training to your phone Connect your (Android) phone to your Computer. Make sure you have USB Debugging activated on your phone. Press the play button in the Unity Editor to deploy your training to your device. Wait for the process to finish. Afterwards, unlock your phone. Your Training should now be deployed to your phone and automatically start. It should also appear as a \"TrainAR\" App, installed on your device in the menu. Test your training If it did not open automatically, open the now deployed application on your phone through the menu. Your phone might ask you if the TrainAR app should be allowed to use your phones camera. Confirm this, as we need the camera to use Augmented Reality. A short tutorial that describes the interaction concept of TrainAR should appear. Navigate through the tutorial/onboarding to start your training. The camera feed of your device should start and you're asked to find a flat surface to scan. Follow these instructions. This should result in the setup you just created being placed onto a table surface. Now you can go through the chain of actions you just defined into the TrainAR Stateflow, which should look roughly like this:"
  },
  "manual/InsightNode.html": {
    "href": "manual/InsightNode.html",
    "title": "Insight Node | TrainAR Documentation",
    "keywords": "Insight Node The TrainAR Insight nodes may be used to show additional insights, hints or tips to the user. Textual insights can also be given in combination with a soundfile (e.g. for voice recordings) and an image may be specified in this node. This could for example be the \"expert\" providing the insights. From the didactic perspective, this is intended to be used to provide additional insights or tips from experience/practise to the user: Telling the user how this would look in practice, telling the user what he should be careful about when training this procedure in real life. It is not intended to provide direct feedback or new instructions to the user. For more detail, read our publication on the TrainAR interaction concept and didactic framework: \"TrainAR: A Scalable Interaction Concept and Didactic Framework for Procedural Trainings Using Handheld Augmented Reality\" TrainAR Node Result"
  },
  "manual/InstructionNode.html": {
    "href": "manual/InstructionNode.html",
    "title": "Instruction Node | TrainAR Documentation",
    "keywords": "Instruction Node With the Instruction node, authors can update the text and the progress percentage on the top panel shown at the top of the smartphone screen. Consequently, authors can specify the instruction text and the progress percentage in the node. From the didactic perspective, this is intended to be used to provide instructions to the user of the training: Telling the user what to do next. For more detail, read our publication on the TrainAR interaction concept and didactic framework: \"TrainAR: A Scalable Interaction Concept and Didactic Framework for Procedural Trainings Using Handheld Augmented Reality\" TrainAR Node Result"
  },
  "manual/NoVisualScripting.html": {
    "href": "manual/NoVisualScripting.html",
    "title": "Advanced Options - AR Beyond the Train__ | TrainAR Documentation",
    "keywords": "Advanced Options - AR Beyond the Train__ TrainAR is mainly aimed towards non-programmers, designer and domain-experts that do have significant media competency but not necessarily programming expertise. Nontheless, TrainAR can also aid the AR development of people with programming skills and Unity expertise. As a central concept, TrainAR is integrated into the Unity Editor as a host software for the simple reason, that this allows people to expand the framework at will to realize trainings outside of the original scope of TrainAR. Several deliberate design decisions were made to keep this possibility and there are multiple options to break out of the TrainAR scope as explained below. Generally, not meant to be a technical documentation but rather an abstract visualization for explanatory purposes of the following documentation: A TrainAR training technically starts with the Prefab Spawning Controller that allows the user to place the training assembly in the environment and signals the Onboarding Controller when and where sufficiently large surfaces were detected. After the assembly is placed, the Interaction Controller is triggered and starts to listen to the Interaction Button Controller . When a Button (e.g. interaction or combination) is pressed, while a TrainAR Object is selected, the TrainAR Object sends a request to change its state in form of a State Information struct to the Statemachine Connector . The Statemachine Connector then hands this State Information to the Visual Statemachine which then checks it against its internal state set by the author of the training and answers to the Statemachine Connector if this request was a valid or invalid request. On the one hand, the Statemachine Connector then hands this information back to the TrainAR Object, which can then trigger object-level behaviours based on this decision (e.g. shading, audio playbacks, outling, animations, Custom events or physics). On the other hand the Statemachine Connector also triggers flow-level Actions for the Questionnaire Controller , Top Panel Controller , Error Overlay Controller , and Direct Info Controller when requested by the Visual Statemachine as a consequence of this action. Unity Visual Scripting Nodes The first and easist possibility is to utilize non-TrainAR Unity Visual Scripting nodes inside of a TrainAR Stateflow. E.g. to delay feedback by using the cooldown node before executing the next TrainAR node as shown in the figure below. This effectively provides the possibility of expanding the flow-level behaviour possibilities of TrainAR to match the Unity Visual Scripting abstraction layer on demand. Switching to the default Unity Editor Secondly, authors can switch to the regular Unity Editor layout by navigating to the TrainAR Tab at the top of the screen and clicking on Open Unity Editor . This can be used to access and customize object-level behaviours like collision, physics, outlining, materials, shaders, transform components, or use the object-level behaviour events that are exposed on the \"TrainAR Object\" and trigger Unity components or custom C# behaviours based on them. This transition is hereby seemless and authors can create a basic flow using the Authoring Tool and then customize more indepth object-level behaviours in the Unity Editor layout if necessary. Using Custom Actions for Advanced Behaviours One way to expand the flow-level behaviours outside of the provided functionality of the TrainAR Framework, while still using the visual scripting component for the Statemachine, is to use Custom Actions. Here, authors can either attach the CustomAction component to a GameObject (not necessarily a TrainAR Object) and call the DynamicTrigger() function or call the CustomAction.StaticTrigger() in the static context from anywhere in the solution. public class CustomAction : MonoBehaviour { public void DynamicTrigger(string parameter) { StaticTrigger(parameter); } public static bool StaticTrigger(string parameter) { return StatemachineConnector.Instance.RequestStateChange(new StateInformation(interactionType:InteractionType.Custom, parameter:parameter)); } } Using TrainAR without the Visual Statemachine Finally, while the visual scripting is an integral part of TrainAR, it is possible to use TrainAR without the visual scripting and the TrainAR visual statemachine component. This can for example be useful to implement non-procedural or rule-based training stateflows or to develop AR learning games based on the framework that only utilize interaction and feedback modalities without the didactic ideas behind TrainAR. As visualized in the technical flow figure, the Visual Statemachine is only communicating with the Statemachine Connector through State Information structs. To disable visual scripting, authors simply need to comment a specific piece of code in the StatemachineConnector in the function RequestStateChange() . Look for this part: acceptedStateChange = stateInformation.interactionType switch { InteractionType.Grab => true, //For grabbing this is always true, selection, deselection and release are not calling this InteractionType.Combine => stateChangeTrigger.Invoke(stateInformation), InteractionType.Interact => stateChangeTrigger.Invoke(stateInformation), InteractionType.Custom => stateChangeTrigger.Invoke(stateInformation), _ => acceptedStateChange }; And and comment it out like this: /* acceptedStateChange = stateInformation.interactionType switch { InteractionType.Grab => true, //For grabbing this is always true, selection, deselection and release are not calling this InteractionType.Combine => stateChangeTrigger.Invoke(stateInformation), InteractionType.Interact => stateChangeTrigger.Invoke(stateInformation), InteractionType.Custom => stateChangeTrigger.Invoke(stateInformation), _ => acceptedStateChange }; */ If authors choose to do this, they have to handle the requested statechange themselves by analyzing the provided State Information struct and returning true or false within the function to communicate the acceptance or denial of the request. The processing of this information is then still handled by the TrainAR framework. They furthermore have to handle the feedback modalities like instructions, feedback UI, questionnaires or expert insights manually. This is possible by just manually calling the methods UpdateTopPanel() , ShowErrorOverlay() , StartQuestionUI() , ShowExpertInsights() , and ShowCompletionOverlay() in the Statemachine Connector to trigger corresponding Actions that are then also automatically executed by the TrainAR framework."
  },
  "manual/ObjectHelperNode.html": {
    "href": "manual/ObjectHelperNode.html",
    "title": "Object Helper Node | TrainAR Documentation",
    "keywords": "Object Helper Node As specified in the TrainAR Objects documentation, TrainAR Objects have states and behaviours. The Object Helper nodeprovides various options to access and modify these from within the TrainAR Stateflow at runtime of the TrainAR training. In the Helper dropwodn menu you can select from the different options. To specifiy which TrainAR Object in the scene you want to modify, specify the exact Object name in the node. TrainAR Node Result Toggle Visibility Check or uncheck the Visible field to make the specified TrainAR Object visible or invisible. Toggle Grabbable Check or uncheck the Grabbable field to make the specified TrainAR Object grabbable or not grabbable. Toggle Interactable Check or uncheck the Interactable field to make the specified TrainAR Object interactable or not interactable. Toggle Combinable Check or uncheck the Combinable field to make the specified TrainAR Object combinable or not combinable. Change Interaction text Changes the labeling of the interaction button when selecting an TrainAR Object. A TrainAR Object is selected when you aim at a TrainAR Object and move close to it. By default the labeling is simply Interact for every TrainAR Object. Change Lerping distance This changes the distance with which a grabbed TrainAR Object floats away from the screen. Generally, you probably want to have bigger TrainAR Objects float at a larger distance than smaller ones. That way, they don't cover the whole screen while grabbing them. Change Mesh and Texture With this option, you can change what a TrainAR Object looks like by changing it's mesh and/or material. This is for example useful if as a result of a combination or interaction an object is supposed to be altered. Get Object Reference This node returns the Unity GameObject Reference of the specified TrainAR Object . For more information about Unity GameObjects, refer to the Unity Documentation . This is mainly useful if you want to utilize Unitys Visual Scripting nodes in the Stateflow as specified in the Advanced Options . Fuse Two Objects This attaches one TrainAR Object to another, making them one. The Object name field specifies the object that is fused onto the object, which is specified in the Fuse to Object field. In the Offset Position and Rotation field the position and rotation relative to the fused with TrainAR Object is specified. Destroy Object Destroys and removes the specified TrainAR Object from the scene."
  },
  "manual/Setup.html": {
    "href": "manual/Setup.html",
    "title": "Installation & Setup | TrainAR Documentation",
    "keywords": "Installation & Setup Download & Install Unity First, download and install the Unity Hub . The Unity Hub allows you to easily install the correct Unity Editor version and corresponding packages that are needed for platform specific deployments. After installing Unity HUB, install Unity Version 2022.1.3f1 as described in the Unity Hub Documentation . When installing Unity, make sure to also indlude the correct modules, depending on which kind of device you want to deploy the TrainAR trainings to: For Android choose Android Build Support. Make sure to have also Android SDK & NDK Tools and OpenJDK checked: For iOS, choose iOS Build Support: You can also install both at the same time to deploy to both devices. This works on every operating system (Linux, Windows and macOS), though for iOS, XCode on macOS is necessary to deploy to iOS devices after building the App. Futhremore, if you do not already have an IDE (Integrated Development Environment) installed and you plan to potentially use C# programming to expand TrainAR, we recommend also installing Microsoft Visual Studio Community 2019 with Unity. Get the TrainAR Authoring Tool After installing Unity we have to setup the TrainAR Authoring tool. There are two ways to accomplish this. Creating a Fork of the TrainAR Repository Manually downloading TrainAR We strongly recommend using the first approach. 1. Creating & Cloning a TrainAR Repository Fork Create a GitHub account. Fork the TrainAR repository into your account Download the GitHub Desktop client Clone the forked repository in the GitHub client Open the Unity HUB Add the now cloned repository through clicking \"Open\" and then selecting the folder that was downloaded in the GitHub client TrainAR should now appear in the list of projects and \"2022.1.0b16\" (or an alternative 2022.1.XXXX version) should be selected as the Editor version. 2. Manually downloading TrainAR Alternatively, you can manually download TrainAR from the GitHub repository as a .zip file, unpack it and then open it in the Unity Hub by clicking \"Open\" and then selecting the folder that was downloaded in the GitHub client. While faster, we dont recommend this approach, as version control is a very helpful tool to prevent losing progress, e.g. because of errors or problems in the TrainAR framework. Opening the TrainAR Authoring Tool To now open the TrainAR Authoring Tool, select the \"TrainAR\" project in the Unity HUB to open it. After Unity is fully loaded, the top-panel menu should show \"TrainAR\" as an option, click this and then \"Open TrainAR Authoring Tool\". You should now see the TrainAR Authoring Tool like this:"
  },
  "manual/StartTrainingNode.html": {
    "href": "manual/StartTrainingNode.html",
    "title": "Start Training Node | TrainAR Documentation",
    "keywords": "Start Training Node The (green) Visual Scripting node called \"TrainAR: Onboarding completed and training assembly placed\" is an event node that is automically executed when the TrainAR framework recognizes that the user of the training finished watching the onboarding, a surface was found and the training assembly was placed by the user. It acts as a starting point for a TrainAR training created by the author. There should be only one \"TrainAR: Onboarding completed and training assembly placed\" node present in a TrainAR Stateflow. Note: While all other TrainAR nodes can be found under Right Click -> \"TrainAR\", the starting node is located under Right Click -> \"Events\". TrainAR Node Result"
  },
  "manual/TrainARBasics.html": {
    "href": "manual/TrainARBasics.html",
    "title": "TrainAR - The Basic Concepts | TrainAR Documentation",
    "keywords": "TrainAR - The Basic Concepts The TrainAR Authoring Tool can be utilized by understanding two basic concepts: The TrainAR Object and the TrainAR Stateflow . If you want to create a TrainAR scenario/training, you have to import 3D models (e.g. from the Assetstore, external websites or from a 3D scanner) and then convert them into TrainAR Objects. Once converted, they automatically inherit TrainAR-specific functionality/behaviours and states (position, rotation, scale, visibility, grabbability, interactability, combinability). TrainAR objects can then be referenced in the TrainAR Stateflow, which determines what action has to be taken next by the user of the TrainAR training and which kind of instruction, insight or feedback should be provided to the user. It additionally can manipulate states of TrainAR Objects during the training. As visualized in this figure, the TrainAR Authoring Tool provides an abstraction layer to easily access both. In blue is the Scene showing all TrainAR Objects currently in the training assembly. Here, their initial state can be manipulated (e.g. they can be positioned, rotated, they can prohibit being grabbed and be invisible at the start of the training). In Red is the TrainAR stateflow, where the flow of the training can be created and altered. The TrainAR Objects and TrainAR Stateflow can be connected by referencing TrainAR Objects in the TrainAR Stateflow by name. The rest is handled by the framework. Features like the onboarding animations, tracking solutions, assembly placement, interaction concepts, layered feedback modalities, expert insights, state management and training assessments are taken care of automatically. Notably, they can also be altered and expanded upon as described in the Advanced Options , if necessary. The following reference video shows the example TrainAR training shipped with the repository. On the left, the deployed TrainAR training is shown from the perspective of the user that is using the training and trying to interact with TrainAR Objects. On the right, the TrainAR Stateflow from the perspective of the author is visualized that determines the training procedure: TrainAR Documentation The TrainAR framework ships with this example training of \"preparing a coffee by using a coffee machine\" to provide a basic point of reference and startingpoint to authors. Beyond that, the documentation provides an Installation & Setup Guide and a Getting Started Guide that explains how to create a very basic, first training scenario in less than half an hour from scratch. Furthermore, a full documentation on TrainAR Objects and the TrainAR Stateflow with all its TrainAR Visual Scripting Nodes is provided. Finally, if experienced authors want to utilize TrainAR beyond the envisioned scope, there is multiple levels of advanced options that provide more powerful customization options to authors as described in the Advanced Options ."
  },
  "manual/TrainARNodes.html": {
    "href": "manual/TrainARNodes.html",
    "title": "TrainAR Nodes | TrainAR Documentation",
    "keywords": "TrainAR Nodes TrainAR Nodes are used in the TrainAR Stateflow to model the behaviour and procedural flow of the AR trainings created with TrainAR. TrainAR Nodes define what the next correct step in your training is but also how your training responds to correct or incorrect actions taken by the user. Consequently, there are TrainAR Nodes which wait for an Action to be taken by the user, these are called TrainAR Actions . TrainAR Actions consist of actions taken in the AR-context (so, grabbing, interacting or combining) or UI-actions (i.e a UI element which pops up and asks the user a question). How your training reacts to correct or incorrect steps taken by the user are defined by TrainAR Insight-, Instruction-, Feedback- and Object Helper Nodes . They are triggered instantly and continue the stateflow automatically after they performed their task. With these, you can instruct the user of the training, define the consequences of the users actions in the AR-context and give feedback or expert insights for these actions in the form of textual information displayed on the UI. Overview TrainAR Node Result Description Starts the TrainAR Stateflow Read more Waits for a Action (Interact, Combine or Custom) Read more Waits for an Action, Forks the Stateflow based on which Action was performed Read more Waits for n Actions to be performed (in any order) Read more Triggers and waits for a UI quiz to be answered Read more Shows new instructions to the user Read more Shows a feedback overlay to the user Read more Shows Insights (e.g. additional tips and tricks) to the user Read more Performs object-level behaviour/state changes Read more Concludes the training and TrainAR Stateflow Read more"
  },
  "manual/TrainArObjects.html": {
    "href": "manual/TrainArObjects.html",
    "title": "Creating and Converting TrainAR Objects | TrainAR Documentation",
    "keywords": "Creating and Converting TrainAR Objects To be able to use 3D assets/models for interactions in TrainAR trainings, you need to convert them to TrainAR Objects first. This gives them default TrainAR functionality/behaviours and makes them usable in the TrainAR Stateflow. To convert a 3D model into a TrainAR Object , simply drag-and-drop it from the project tab into the hierarchy tab. Then right click on it in the hierarchy tab and select Convert to TrainAR Object . If the 3D model you're trying to convert is packed as a so-called \"Prefab\" (this is the case if they appear blue in the Hierarchy), you'll also have to \"Unpack Completely\" it first. This is often the case for 3D models from the Unity Assetstore. 3D models from 3D scanners or third-party 3D model libraries are rarely packed as Prefabs. Note: An object may only be converted to a TrainAR Object, if was not already converted and it has a Transform, MeshFilter and a MeshRenderer applied to it. SkinnedMeshRenderers are currently not supported. Object States A TrainAR Object has certain state attributes with which you can control in which kinds of ways the object can be interacted with. These states are: Visible: Whether or not this TrainAR Object is visible or invisible. Grabbable: If this is enabled, objects may be grabbed and moved around by the user. Therefore this should be disabled, in case of stationary objects. Interactable: Whether or not it is possible to trigger interactions on this object. Combineable: Whether or not it is possible to combine other TrainAR objects with it. If you have selected a TrainAR Object in the Authoring Tool, you can alter the state TrainAR objects start the training with by clicking on them in the Object State Toolbar . Note: You can also change TrainAR object states during the training through the Object Helper Node in the TrainAR Stateflow. Transform Tools With the Transform Tools you can configure your TrainAR Objects further. For example, you can move, rotate, or scale objects and alter their Bounding Box. The Transform tool is a convenient combination of the previous tools. With the Bounding Box Tool you can configure the bounding box of the object, which among other things, defines at what point TrainAR Objects are overlapping, so they can be combined with each other. Tip: Holding alt and clicking pins the center in place and clicking shift makes it possible to scale the bounding box uniformly. Object-level Behaviours Nothing to do here for now. TrainAR Objects automatically inherit all necessary behaviours like physics, collisions, outlining, sounds, shadows, interactions and many more for TrainAR to work consistently. There might be cases where you want more than what is provided. E.g. playing a specific sound on a specific combination of two objects, outlining this specific object on selection in pink (for some reason) or showing a cat GIF when this object is interacted with. How to accomplish these object-level behaviours by listening to TrainAR Object interaction events is described in the Advanced Options ."
  },
  "manual/TrainingConclusionNode.html": {
    "href": "manual/TrainingConclusionNode.html",
    "title": "Training Conclusion Node | TrainAR Documentation",
    "keywords": "Training Conclusion Node The \"TrainAR: Training Conclusion\" node is the end of the TrainAR stateflow and training. It opens a training assessment, providing an overview with various performance metrics, accumulated over the training. This e.g. includes a graph displaying the number of incorrect actions performed by the user during the training. There should be only one \"TrainAR: Training Conclusion\" node present in a TrainAR Stateflow but it can be triggered from multiple Outputs from different stateflows of the training. TrainAR Node Result"
  },
  "manual/UIActionNodes.html": {
    "href": "manual/UIActionNodes.html",
    "title": "TrainAR UI Action | TrainAR Documentation",
    "keywords": "TrainAR UI Action TrainAR: Action (UI) nodes trigger UI quizes/questionnaires for the user to complete in the TrainAR training. UI Action notes require input of the user on the user interface and the UI Action node includes different types of quizes/questionnaires in form of UI elements. To select which questionnaire type you want to use, you may change via the dropdown menu UI-Task: Questionnaire, Input Field or list selection actions. UI Task: Questionnaire If the UI Task is set to Questionnaire , the user will be shown a question and a set of predetermined answers. When the user chooses one of these answers, the user is also shown feedback. The question itself as well as the number of corresponding correct and wrong answers and their feedback have to be specified in the node. The questionnare can have between 2 and 4 possible answers. If the user inputs an answer, the stateflow resumes according to the Correct or Incorrect outputs of the node. Questionnaire nodes can also fork the Stateflow based on the given answer. TrainAR Node Result UI Task: Input Field With the UI Task set to Input Field , the user has to type in his answer to a question via the smartphones on-screen keyboard. The questions as well as all correct answers have to be specified in the node. If the user inputs an answer, the stateflow resumes according to the Correct or Incorrect outputs of the node depending on if the users answers is one of the specified correct answers or not. TrainAR Node Result UI Task: List Selection With the UI Task set to List Selection , the user is presented with a scrollable list of possible anwers, which can be defined, as well as their respective feedback, in the node. If the user chooses all correct items in the list, the Correct output is triggered. TrainAR Node Result"
  },
  "manual/VisualScripting.html": {
    "href": "manual/VisualScripting.html",
    "title": "Creating a TrainAR Stateflow | TrainAR Documentation",
    "keywords": "Creating a TrainAR Stateflow By creating a TrainAR Stateflow, you describe the procedural sequences of actions for the training you create with TrainAR. In essence, this stateflow describes at which points, which actions are expected of the user and how TrainAR reacts to those actions. For the example TrainAR training, that is shipped with the repository, the created TrainAR Training with its corresponding TrainAR Stateflow looks like this: TrainAR Nodes: The Starting Node A \"node\" is simply one element of the TrainAR stateflow. For example, the TrainAR: Onboarding completed and training assembly placed node acts as a starting point for your TrainAR Stateflow. The stateflow continues from this point, as soon as the training setup is placed. There always has to be exactly one Starting Node present in the stateflow. Connecting Node Inputs & Outputs TrainAR Nodes have various inputs and outputs. By connecting the nodes with eachother, you control the procedural flow of your training. Connecting nodes is done by connecting an output of one node with the input of another. One output can only be connected to one Input of the next node but one Input can be used from several outputs. How to fork a TrainAR Stateflow is described in detail in the Action Node documentation. TrainAR comes with 10 TrainAR-specific nodes that can be connected with each other. They are described in detail in the TrainAR Nodes documentation. As desrribed in the Advanced Options , Unitys Visual Scripting nodes can also be incorporated into the TrainAR Stateflow. Referencing TrainAR Objects in TrainAR Nodes With some nodes in TrainAR you want to reference specific TrainAR Objects , most notably, TrainAR: Action and TrainAR: Object Helper nodes . Referencing TrainAR Objects in a node is done by using the name of the TrainAR Object . This loose coupling between TrainAR Objects and the TrainAR Stateflow is deliberate as it allows to work on both independently but it requires you to use the exact name. So pay attention to upper and lower case letters as referencing by name is case sensitive. Referencing a TrainAR Object by name in the TrainAR Stateflow could for example look something like this: In this example, there is a cup as a TrainAR Object in the Hierarchy of the scene. If you want to reference this \"Cup\" in a node you simply have to use the exact name of the TrainAR Object as it is in the hierarchy as a reference. This is done in the TrainAR: Action node in the Correct object field. Conditional Outputs Some nodes have multiple outputs, which get triggered depending on what happened in your training. For example you probably want to react differently to a correct action of a user compared to an incorrect action. Consequently, Action nodes have multiple, conditional outputs. For example, if you want an \"Interaction\" on the cup by the user you could proceed to a new Action node if the user performs this action but if the user performs an incorrect action, you want to show a Feedback overlay that provides the user with additional instructions or help: The correct user action at this state is an interact on the \"Cup\" TrainAR Object. If this occures, the stateflow continues with the \"Correct\" Output, otherwise according With the \"Incorrect\" Output and displays a error feedback on the UI. Since the Incorrect path ends after the feedback node, the stateflow returns to the previous TrainAR Action node and waits for the next input by the user."
  }
}